{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA 3D Feature Extraction - Refactored Workflow Demonstration\n",
    "\n",
    "This notebook demonstrates the refactored RNA 3D Feature Extractor architecture, showing how the modular components work together to extract, validate, and analyze RNA features.\n",
    "\n",
    "## Refactored Architecture\n",
    "\n",
    "The refactored codebase is organized into these primary modules:\n",
    "\n",
    "- **DataManager**: Handles data loading, saving, and I/O operations\n",
    "- **FeatureExtractor**: Manages thermodynamic and MI feature extraction\n",
    "- **BatchProcessor**: Coordinates processing multiple RNA targets\n",
    "- **MemoryMonitor**: Tracks memory usage during processing\n",
    "- **ResultValidator**: Validates the quality and compatibility of features\n",
    "\n",
    "These components work together through the integrated **RNAFeatureExtractionWorkflow** class to provide a complete feature extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Add project root to path to allow importing modules\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    # If we're in the notebooks directory, go up one level\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "else:\n",
    "    # Otherwise, assume we're in the project root\n",
    "    project_root = os.getcwd()\n",
    "    \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import our modules\n",
    "from src.data.data_manager import DataManager\n",
    "from src.features.feature_extractor import FeatureExtractor\n",
    "from src.processing.batch_processor import BatchProcessor\n",
    "from src.analysis.memory_monitor import MemoryMonitor\n",
    "from src.validation.result_validator import ResultValidator\n",
    "from src.workflow import RNAFeatureExtractionWorkflow\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Individual Components\n",
    "\n",
    "First, let's see how each component works individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 DataManager\n",
    "\n",
    "The DataManager handles data loading, saving, and I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataManager instance\n",
    "data_manager = DataManager(base_dir=\"data\")\n",
    "\n",
    "# List available target IDs\n",
    "csv_path = \"data/targets.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    targets_df = data_manager.load_rna_data(csv_path)\n",
    "    target_ids = data_manager.get_unique_target_ids(targets_df)\n",
    "    print(f\"Found {len(target_ids)} target IDs in {csv_path}\")\n",
    "    print(f\"First 5 target IDs: {target_ids[:5]}\")\n",
    "else:\n",
    "    # Define a sample target ID for demonstration\n",
    "    target_ids = [\"R1107\", \"R1108\", \"R1117v2\"]\n",
    "    print(f\"Using sample target IDs: {target_ids}\")\n",
    "    \n",
    "# Set up a test target ID for demonstration\n",
    "if target_ids:\n",
    "    test_target_id = target_ids[0]\n",
    "    print(f\"Using test target ID: {test_target_id}\")\n",
    "else:\n",
    "    test_target_id = \"R1107\"\n",
    "    print(f\"Using default test target ID: {test_target_id}\")\n",
    "\n",
    "# Try to load the sequence for the test target\n",
    "try:\n",
    "    sequence = data_manager.get_sequence_for_target(test_target_id)\n",
    "    print(f\"Loaded sequence for {test_target_id}: {sequence[:50]}... (length: {len(sequence)})\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load sequence for {test_target_id}: {e}\")\n",
    "    # Create a dummy sequence for demonstration\n",
    "    sequence = \"GAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUCGAUC\"\n",
    "    print(f\"Using dummy sequence: {sequence[:50]}... (length: {len(sequence)})\")\n",
    "\n",
    "# Try to load MSA data for the test target\n",
    "try:\n",
    "    msa_sequences = data_manager.load_msa_data(test_target_id)\n",
    "    print(f\"Loaded MSA data for {test_target_id}: {len(msa_sequences)} sequences\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load MSA data for {test_target_id}: {e}\")\n",
    "    # Create dummy MSA sequences for demonstration\n",
    "    msa_sequences = [sequence] * 3  # Single-sequence MSA\n",
    "    print(f\"Using dummy MSA data: {len(msa_sequences)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 MemoryMonitor\n",
    "\n",
    "The MemoryMonitor tracks memory usage during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a MemoryMonitor instance\n",
    "memory_monitor = MemoryMonitor()\n",
    "\n",
    "# Log current memory usage\n",
    "memory_monitor.log_memory_usage(\"Initial memory usage\")\n",
    "\n",
    "# Demonstrate memory tracking with context manager\n",
    "with memory_monitor.track(\"Allocating memory\"):\n",
    "    # Allocate some memory to see the effect\n",
    "    data = [0] * 10**7\n",
    "    time.sleep(1)\n",
    "\n",
    "# Get current memory usage\n",
    "current_memory = memory_monitor.get_current_memory_usage()\n",
    "print(f\"Current memory usage: {current_memory:.2f} GB\")\n",
    "\n",
    "# Plot memory usage\n",
    "memory_monitor.plot_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 FeatureExtractor\n",
    "\n",
    "The FeatureExtractor handles extracting thermodynamic and mutual information features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a FeatureExtractor instance\n",
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Extract thermodynamic features for a short sequence to demonstrate\n",
    "demo_sequence = \"GGGAAAACCC\"  # Short sequence for demonstration\n",
    "print(f\"Extracting thermodynamic features for sequence: {demo_sequence}\")\n",
    "\n",
    "with memory_monitor.track(\"Extracting thermodynamic features\"):\n",
    "    thermo_features = feature_extractor.extract_thermodynamic_features(demo_sequence)\n",
    "\n",
    "# Display the extracted thermodynamic features\n",
    "print(\"\\nExtracted thermodynamic features:\")\n",
    "for key, value in thermo_features.items():\n",
    "    if isinstance(value, np.ndarray) and value.ndim > 0 and value.size > 10:\n",
    "        print(f\"  {key}: ndarray with shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract MI features for a simple MSA to demonstrate\n",
    "demo_msa = [\n",
    "    \"GGGAAAACCC\",\n",
    "    \"GGGAAAACCC\",\n",
    "    \"GGGAAAACCC\"\n",
    "]\n",
    "print(f\"\\nExtracting MI features for MSA with {len(demo_msa)} sequences\")\n",
    "\n",
    "with memory_monitor.track(\"Extracting MI features\"):\n",
    "    mi_features = feature_extractor.extract_mi_features(demo_msa)\n",
    "\n",
    "# Display the extracted MI features\n",
    "print(\"\\nExtracted MI features:\")\n",
    "for key, value in mi_features.items():\n",
    "    if isinstance(value, np.ndarray) and value.ndim > 0 and value.size > 10:\n",
    "        print(f\"  {key}: ndarray with shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract all features at once\n",
    "print(f\"\\nExtracting all features for test target: {test_target_id}\")\n",
    "\n",
    "with memory_monitor.track(\"Extracting all features\"):\n",
    "    all_features = feature_extractor.extract_features(\n",
    "        target_id=test_target_id,\n",
    "        sequence=sequence,\n",
    "        msa_sequences=msa_sequences,\n",
    "        extract_thermo=True,\n",
    "        extract_mi=True\n",
    "    )\n",
    "\n",
    "# Display the feature types extracted\n",
    "print(\"\\nExtracted feature types:\")\n",
    "for feature_type, features in all_features.items():\n",
    "    print(f\"  {feature_type}: {len(features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 ResultValidator\n",
    "\n",
    "The ResultValidator validates the quality and compatibility of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a ResultValidator instance\n",
    "result_validator = ResultValidator(data_manager=data_manager)\n",
    "\n",
    "# Validate the thermodynamic features we just extracted\n",
    "print(\"Validating thermodynamic features:\")\n",
    "thermo_validation = result_validator.validate_thermodynamic_features(thermo_features)\n",
    "print(f\"  Valid: {thermo_validation['is_valid']}\")\n",
    "print(f\"  Issues: {thermo_validation['issues']}\")\n",
    "print(f\"  Warnings: {thermo_validation['warnings']}\")\n",
    "print(f\"  Stats: {thermo_validation['stats']}\")\n",
    "\n",
    "# Validate MI features\n",
    "print(\"\\nValidating MI features:\")\n",
    "mi_validation = result_validator.validate_mi_features(mi_features)\n",
    "print(f\"  Valid: {mi_validation['is_valid']}\")\n",
    "print(f\"  Issues: {mi_validation['issues']}\")\n",
    "print(f\"  Warnings: {mi_validation['warnings']}\")\n",
    "print(f\"  Stats: {mi_validation['stats']}\")\n",
    "\n",
    "# Validate feature compatibility\n",
    "print(\"\\nValidating feature compatibility:\")\n",
    "compatibility_validation = result_validator.validate_feature_compatibility({\n",
    "    \"thermo_features\": thermo_features,\n",
    "    \"mi_features\": mi_features\n",
    "})\n",
    "print(f\"  Valid: {compatibility_validation['is_valid']}\")\n",
    "print(f\"  Issues: {compatibility_validation['issues']}\")\n",
    "print(f\"  Warnings: {compatibility_validation['warnings']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 BatchProcessor\n",
    "\n",
    "The BatchProcessor coordinates processing multiple RNA targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a BatchProcessor instance\n",
    "batch_processor = BatchProcessor(\n",
    "    data_manager=data_manager,\n",
    "    feature_extractor=feature_extractor,\n",
    "    memory_monitor=memory_monitor,\n",
    "    output_dir=\"data/processed\",\n",
    "    log_dir=\"data/processed/logs\",\n",
    "    max_memory_usage_gb=16.0,\n",
    "    batch_size=5\n",
    ")\n",
    "\n",
    "# Process a small batch of targets (if available, otherwise use dummy targets)\n",
    "if len(target_ids) >= 3:\n",
    "    batch_target_ids = target_ids[:3]\n",
    "else:\n",
    "    batch_target_ids = [\"dummy_target_1\", \"dummy_target_2\", \"dummy_target_3\"]\n",
    "\n",
    "print(f\"Processing batch of {len(batch_target_ids)} targets: {batch_target_ids}\")\n",
    "\n",
    "# For demonstration purposes, allow the code to continue even if the batch processing fails\n",
    "try:\n",
    "    with memory_monitor.track(\"Batch processing\"):\n",
    "        batch_results = batch_processor.process_targets(\n",
    "            target_ids=batch_target_ids,\n",
    "            extract_thermo=True,\n",
    "            extract_mi=True,\n",
    "            save_intermediates=True,\n",
    "            batch_name=\"demo_batch\"\n",
    "        )\n",
    "    \n",
    "    # Display batch processing results\n",
    "    print(\"\\nBatch processing results:\")\n",
    "    print(f\"  Total targets: {batch_results['total_targets']}\")\n",
    "    print(f\"  Successful targets: {batch_results['successful_targets']}\")\n",
    "    print(f\"  Skipped targets: {batch_results['skipped_targets']}\")\n",
    "    \n",
    "    # Validate batch results\n",
    "    batch_validation = result_validator.validate_batch_results(batch_results)\n",
    "    print(\"\\nBatch validation results:\")\n",
    "    print(f\"  Valid targets: {batch_validation['valid_targets']}\")\n",
    "    print(f\"  Invalid targets: {batch_validation['invalid_targets']}\")\n",
    "    print(f\"  Targets with warnings: {batch_validation['targets_with_warnings']}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nBatch processing failed: {e}\")\n",
    "    print(\"Continuing with demonstration using the integrated workflow...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Integrated Workflow\n",
    "\n",
    "Now, let's use the integrated RNAFeatureExtractionWorkflow class to run the complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a workflow instance\n",
    "workflow = RNAFeatureExtractionWorkflow(\n",
    "    data_dir=\"data\",\n",
    "    output_dir=\"data/processed\",\n",
    "    log_dir=\"data/processed/logs\",\n",
    "    memory_plot_dir=\"data/processed/memory_plots\",\n",
    "    validation_report_dir=\"data/processed/validation_reports\",\n",
    "    max_memory_gb=16.0,\n",
    "    batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extracting Features for a Single Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract features for a single target\n",
    "print(f\"Extracting features for single target: {test_target_id}\")\n",
    "\n",
    "try:\n",
    "    single_target_results = workflow.extract_single_target(\n",
    "        target_id=test_target_id,\n",
    "        extract_thermo=True,\n",
    "        extract_mi=True,\n",
    "        validate_results=True,\n",
    "        save_memory_plot=True\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nSingle target extraction results:\")\n",
    "    print(f\"  Target ID: {single_target_results['target_id']}\")\n",
    "    print(f\"  Features extracted: {single_target_results['features_extracted']}\")\n",
    "    print(f\"  Execution time: {single_target_results['execution_time']:.2f} seconds\")\n",
    "    print(f\"  Peak memory usage: {single_target_results['peak_memory_gb']:.2f} GB\")\n",
    "    \n",
    "    if 'validation' in single_target_results:\n",
    "        print(\"  Validation:\")\n",
    "        print(f\"    Valid: {single_target_results['validation']['is_valid']}\")\n",
    "        print(f\"    Issues: {single_target_results['validation']['issues_count']}\")\n",
    "        print(f\"    Warnings: {single_target_results['validation']['warnings_count']}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nSingle target extraction failed: {e}\")\n",
    "    print(\"This could be due to missing data files. Continuing with demonstration...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Targets File for Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a targets file for demonstration\n",
    "targets_file = \"data/demo_targets.txt\"\n",
    "os.makedirs(os.path.dirname(targets_file), exist_ok=True)\n",
    "\n",
    "# Write target IDs to the file (use real targets if available, otherwise use dummy targets)\n",
    "if len(target_ids) >= 3:\n",
    "    demo_targets = target_ids[:3]\n",
    "else:\n",
    "    demo_targets = [\"dummy_target_1\", \"dummy_target_2\", \"dummy_target_3\"]\n",
    "\n",
    "with open(targets_file, 'w') as f:\n",
    "    for target_id in demo_targets:\n",
    "        f.write(f\"{target_id}\\n\")\n",
    "\n",
    "print(f\"Created targets file: {targets_file} with {len(demo_targets)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Running the Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the complete workflow\n",
    "print(f\"Running complete workflow for targets in {targets_file}\")\n",
    "\n",
    "try:\n",
    "    workflow_results = workflow.run_extraction(\n",
    "        targets_file=targets_file,\n",
    "        extract_thermo=True,\n",
    "        extract_mi=True,\n",
    "        batch_name=\"demo_workflow\",\n",
    "        validate_results=True,\n",
    "        save_memory_plots=True\n",
    "    )\n",
    "    \n",
    "    # Display workflow results\n",
    "    print(\"\\nWorkflow results:\")\n",
    "    print(f\"  Batch name: {workflow_results['batch_name']}\")\n",
    "    print(f\"  Total targets: {workflow_results['total_targets']}\")\n",
    "    print(f\"  Successful targets: {workflow_results['successful_targets']}\")\n",
    "    print(f\"  Skipped targets: {workflow_results['skipped_targets']}\")\n",
    "    print(f\"  Execution time: {workflow_results['execution_time']:.2f} seconds\")\n",
    "    print(f\"  Peak memory usage: {workflow_results['peak_memory_gb']:.2f} GB\")\n",
    "    \n",
    "    if 'validation' in workflow_results:\n",
    "        print(\"  Validation:\")\n",
    "        print(f\"    Valid targets: {workflow_results['validation']['valid_targets']}\")\n",
    "        print(f\"    Invalid targets: {workflow_results['validation']['invalid_targets']}\")\n",
    "        print(f\"    Targets with warnings: {workflow_results['validation']['targets_with_warnings']}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nWorkflow execution failed: {e}\")\n",
    "    print(\"This could be due to missing data files or other issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing Results\n",
    "\n",
    "Let's load and analyze the results of our feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we have output files\n",
    "thermo_features_dir = \"data/processed/thermo_features\"\n",
    "mi_features_dir = \"data/processed/mi_features\"\n",
    "\n",
    "# List available feature files\n",
    "thermo_files = []\n",
    "mi_files = []\n",
    "\n",
    "if os.path.exists(thermo_features_dir):\n",
    "    thermo_files = [f for f in os.listdir(thermo_features_dir) if f.endswith(\".npz\")]\n",
    "    print(f\"Found {len(thermo_files)} thermodynamic feature files\")\n",
    "else:\n",
    "    print(f\"Thermodynamic features directory not found: {thermo_features_dir}\")\n",
    "    \n",
    "if os.path.exists(mi_features_dir):\n",
    "    mi_files = [f for f in os.listdir(mi_features_dir) if f.endswith(\".npz\")]\n",
    "    print(f\"Found {len(mi_files)} MI feature files\")\n",
    "else:\n",
    "    print(f\"MI features directory not found: {mi_features_dir}\")\n",
    "\n",
    "# If we have feature files, load and display one\n",
    "if thermo_files:\n",
    "    sample_thermo_file = os.path.join(thermo_features_dir, thermo_files[0])\n",
    "    print(f\"\\nLoading sample thermodynamic features file: {sample_thermo_file}\")\n",
    "    \n",
    "    thermo_features = np.load(sample_thermo_file, allow_pickle=True)\n",
    "    print(\"Feature keys:\")\n",
    "    for key in thermo_features.keys():\n",
    "        feature = thermo_features[key]\n",
    "        if isinstance(feature, np.ndarray) and feature.ndim > 0 and feature.size > 10:\n",
    "            print(f\"  {key}: ndarray with shape {feature.shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {feature}\")\n",
    "            \n",
    "if mi_files:\n",
    "    sample_mi_file = os.path.join(mi_features_dir, mi_files[0])\n",
    "    print(f\"\\nLoading sample MI features file: {sample_mi_file}\")\n",
    "    \n",
    "    mi_features = np.load(sample_mi_file, allow_pickle=True)\n",
    "    print(\"Feature keys:\")\n",
    "    for key in mi_features.keys():\n",
    "        feature = mi_features[key]\n",
    "        if isinstance(feature, np.ndarray) and feature.ndim > 0 and feature.size > 10:\n",
    "            print(f\"  {key}: ndarray with shape {feature.shape}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Features\n",
    "\n",
    "Let's visualize some of the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize pairing probabilities matrix if available\n",
    "if 'thermo_features' in locals() and 'struct.pairing_probs' in thermo_features:\n",
    "    pairing_probs = thermo_features['struct.pairing_probs']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(pairing_probs, cmap='viridis')\n",
    "    plt.colorbar(label='Pairing Probability')\n",
    "    plt.title('RNA Base Pairing Probabilities')\n",
    "    plt.xlabel('Nucleotide Position')\n",
    "    plt.ylabel('Nucleotide Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif 'thermo_features' in locals() and 'pairing_probs' in thermo_features:\n",
    "    pairing_probs = thermo_features['pairing_probs']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(pairing_probs, cmap='viridis')\n",
    "    plt.colorbar(label='Pairing Probability')\n",
    "    plt.title('RNA Base Pairing Probabilities')\n",
    "    plt.xlabel('Nucleotide Position')\n",
    "    plt.ylabel('Nucleotide Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pairing probabilities matrix not available for visualization\")\n",
    "    \n",
    "# Visualize MI coupling matrix if available\n",
    "if 'mi_features' in locals() and 'mi.coupling_matrix' in mi_features:\n",
    "    coupling_matrix = mi_features['mi.coupling_matrix']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(coupling_matrix, cmap='plasma')\n",
    "    plt.colorbar(label='Mutual Information')\n",
    "    plt.title('RNA Mutual Information Coupling Matrix')\n",
    "    plt.xlabel('Nucleotide Position')\n",
    "    plt.ylabel('Nucleotide Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif 'mi_features' in locals() and 'coupling_matrix' in mi_features:\n",
    "    coupling_matrix = mi_features['coupling_matrix']\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(coupling_matrix, cmap='plasma')\n",
    "    plt.colorbar(label='Mutual Information')\n",
    "    plt.title('RNA Mutual Information Coupling Matrix')\n",
    "    plt.xlabel('Nucleotide Position')\n",
    "    plt.ylabel('Nucleotide Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"MI coupling matrix not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Review of Refactored Architecture\n",
    "\n",
    "The refactored RNA 3D Feature Extractor architecture provides several key advantages:\n",
    "\n",
    "1. **Modularity**: Each component has a well-defined responsibility, making the code easier to understand, maintain, and extend.\n",
    "\n",
    "2. **Memory Efficiency**: The architecture includes built-in memory monitoring and optimization, with the ability to process targets in batches to prevent out-of-memory errors.\n",
    "\n",
    "3. **Validation**: The ResultValidator component ensures that extracted features meet quality standards and are compatible with downstream models.\n",
    "\n",
    "4. **Fault Tolerance**: The system can recover from errors in individual targets and continue processing other targets.\n",
    "\n",
    "5. **Flexibility**: The architecture supports different feature types, data sources, and processing configurations.\n",
    "\n",
    "6. **Maintainability**: Clear separation of concerns makes it easier to update or replace individual components without affecting the rest of the system.\n",
    "\n",
    "7. **Performance Monitoring**: Built-in memory and performance tracking helps identify bottlenecks and optimize resource usage.\n",
    "\n",
    "This refactored architecture provides a solid foundation for future enhancements and integrations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}